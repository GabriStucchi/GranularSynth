{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabriStucchi/GranularSynth/blob/master/dcase_autoencoder_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7l-rSR-mxz5Z"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import math\n",
        "import sys\n",
        "import gc\n",
        "import csv\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, UpSampling2D, Flatten, Dense, BatchNormalization, LeakyReLU, Add, Softmax, Layer, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import L2\n",
        "from sklearn import metrics\n",
        "import random\n",
        "\n",
        "import librosa\n",
        "from librosa import display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqpX-dGfGnTz",
        "outputId": "b43a6579-49f0-4bac-8a57-ae4a1e713dfe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n",
            "Tue Apr 12 13:15:55 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive/DCASE2020\n",
        "%ls"
      ],
      "metadata": {
        "id": "4zJoYBx0nhtu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f683e926-3199-4286-bff7-0bb0731863bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/DCASE2020\n",
            "\u001b[0m\u001b[01;34m2D_autoencoder_result\u001b[0m/        \u001b[01;34mclassification_result\u001b[0m/    \u001b[01;34mlogs\u001b[0m/\n",
            "baseline.yaml                 class_train_baseline.log  train_baseline.log\n",
            "classification_baseline.yaml  \u001b[01;34mdev_data\u001b[0m/\n",
            "\u001b[01;34mclassification_model\u001b[0m/         id_assignment.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoYLW9lAzXF8"
      },
      "source": [
        "# **Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rMb-BuJWzZhw"
      },
      "outputs": [],
      "source": [
        "DEV_DATA_SIZE = 20119\n",
        "RANDOM_SEED = 42    # Random seed for reproducibility\n",
        "DATA_DIR = './dev_data'\n",
        "MODEL_DIR = './autoencoder_model'\n",
        "RESULT_DIR = './autoencoder_result'\n",
        "RESULT_FILE = 'result.csv'\n",
        "\n",
        "SAMPLE_RATE = 16000\n",
        "DURATION = 10\n",
        "MAX_FPR = 0.1\n",
        "\n",
        "# Fit parameters\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 512\n",
        "LEARNING_RATE = 0.001\n",
        "LOSS = 'mean_squared_error'\n",
        "\n",
        "feature = {\n",
        "    'n_mels': 128,\n",
        "    'n_fft': 1024,\n",
        "    'hop_length': 512,\n",
        "    'n_frames': 5,\n",
        "    'power': 2.0\n",
        "}\n",
        "\n",
        "machine_ids = {\n",
        "    'fan': ['00', '02', '04', '06'],\n",
        "    'pump': ['00', '02', '04', '06'],\n",
        "    'slider': ['00', '02', '04', '06'],\n",
        "    'valve': ['00', '02', '04', '06'],\n",
        "    'ToyCar': ['01', '02', '03', '04'],\n",
        "    'ToyConveyor': ['01', '02', '03']\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eurn65cE0bDm"
      },
      "source": [
        "# **Utils**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wtcexo6x0f1t"
      },
      "outputs": [],
      "source": [
        "def plot_history(history):\n",
        "    \"\"\"\n",
        "    history : tf.keras.callbacks.History\n",
        "        training history\n",
        "    return : None\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15,5))\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend(('Training', 'Validation'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QixSMIwBtw-8"
      },
      "outputs": [],
      "source": [
        "def save_figure(name):\n",
        "    \"\"\"\n",
        "    name : str\n",
        "        save png file path\n",
        "    return : None\n",
        "    \"\"\"\n",
        "    plt.savefig(name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reshape_spec(spectrogram, n_frames=feature['n_frames']):\n",
        "    '''\n",
        "    Reshape the spectrogram to have rows composed of n_frames consecutive frames\n",
        "    spectrogram: numpy.array ( numpy.array ( float ) )\n",
        "        the spectrogram to reshape\n",
        "    frames: int \n",
        "        number of frames to concatenate (default = 5)\n",
        "    return\n",
        "        feature: numpy.array ( numpy.array ( float ) )\n",
        "            the reshaped spectrogram (to concatenate)\n",
        "    '''\n",
        "    n_mels = len(spectrogram[:, 0])\n",
        "    n_time = len(spectrogram[0, :])\n",
        "\n",
        "    n_rows = n_time - n_frames + 1\n",
        "    n_col = n_mels*n_frames\n",
        "    feature = np.zeros((n_rows, n_col))\n",
        "\n",
        "    # generate feature matrix by concatenating multiple frames\n",
        "    for t in range(n_frames):\n",
        "        feature[:, n_mels*t:n_mels*(t+1)] = spectrogram[:, t:t+n_rows].T\n",
        "\n",
        "    return feature"
      ],
      "metadata": {
        "id": "YQpQes5pJDL8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_csv(save_file_path,\n",
        "             save_data):\n",
        "    with open(save_file_path, \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f, lineterminator='\\n')\n",
        "        writer.writerows(save_data)"
      ],
      "metadata": {
        "id": "gsHfw_hKsDy2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyY9FwJzyG4f"
      },
      "source": [
        "# **Model definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rbSBZ70-Qw47"
      },
      "outputs": [],
      "source": [
        "def get_model(inputDim):\n",
        "    \"\"\"\n",
        "    model based on the simple dense auto encoder \n",
        "    (128*128*128*128*8*128*128*128*128)\n",
        "    \"\"\"\n",
        "    inputLayer = Input(shape=(inputDim,))\n",
        "\n",
        "    h = Dense(128)(inputLayer)\n",
        "    h = BatchNormalization()(h)\n",
        "    h = Activation('relu')(h)\n",
        "\n",
        "    h = Dense(128)(h)\n",
        "    h = BatchNormalization()(h)\n",
        "    h = Activation('relu')(h)\n",
        "\n",
        "    h = Dense(128)(h)\n",
        "    h = BatchNormalization()(h)\n",
        "    h = Activation('relu')(h)\n",
        "\n",
        "    h = Dense(128)(h)\n",
        "    h = BatchNormalization()(h)\n",
        "    h = Activation('relu')(h)\n",
        "    \n",
        "    h = Dense(8)(h)\n",
        "    h = BatchNormalization()(h)\n",
        "    h = Activation('relu')(h)\n",
        "\n",
        "    h = Dense(128)(h)\n",
        "    h = BatchNormalization()(h)\n",
        "    h = Activation('relu')(h)\n",
        "\n",
        "    h = Dense(128)(h)\n",
        "    h = BatchNormalization()(h)\n",
        "    h = Activation('relu')(h)\n",
        "\n",
        "    h = Dense(128)(h)\n",
        "    h = BatchNormalization()(h)\n",
        "    h = Activation('relu')(h)\n",
        "\n",
        "    h = Dense(128)(h)\n",
        "    h = BatchNormalization()(h)\n",
        "    h = Activation('relu')(h)\n",
        "\n",
        "    h = Dense(inputDim)(h)\n",
        "\n",
        "    return Model(inputs=inputLayer, outputs=h)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qjn6-eSBiTYy"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the data"
      ],
      "metadata": {
        "id": "YKVvBlJaKDGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "machine = 'fan'\n",
        "\n",
        "csv_lines = []\n",
        "csv_lines.append([machine])\n",
        "csv_lines.append([\"id\", \"AUC\", \"pAUC\"])\n",
        "as_csv = []\n",
        "as_csv.append([machine])\n",
        "as_csv.append(['GT', 'AS'])\n",
        "performance = []\n",
        "\n",
        "for id in machine_ids[machine]:\n",
        "    data_path = '{data_dir}/train/{m}/id_{id}/*.npy'.format(data_dir=DATA_DIR, m=machine, id=id)\n",
        "    paths = glob.glob(data_path)\n",
        "\n",
        "    print('\\n========== LOADING {m}: id_{id} DATA =========='.format(m=machine, id=id))\n",
        "    for idx, path in tqdm(enumerate(paths)):\n",
        "        spec = np.load(path)\n",
        "        feature = reshape_spec(spec)\n",
        "        if idx==0:\n",
        "            X = feature\n",
        "        else:\n",
        "            X = np.concatenate((X, feature), axis=0)\n",
        "    print('Training matrix shape: {}'.format(X.shape))\n",
        "\n",
        "    model = get_model(inputDim=X.shape[1])\n",
        "    model.summary()\n",
        "\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "    model.compile(optimizer=opt, loss=LOSS)\n",
        "\n",
        "    print('========== START {m}: id_{id} TRAINING =========='.format(m=machine, id=id))\n",
        "    history = model.fit(x = X,\n",
        "                        y = X,\n",
        "                        epochs = EPOCHS,\n",
        "                        batch_size = BATCH_SIZE,\n",
        "                        shuffle=True,\n",
        "                        validation_split=0.1,\n",
        "                        verbose = 1)\n",
        "    print('========== END TRAINING ==========')\n",
        "    plot_history(history)\n",
        "\n",
        "    #\n",
        "    #   TESTING\n",
        "    #\n",
        "\n",
        "    data_path = '{data_dir}/test/{m}/id_{id}/*.npy'.format(data_dir=DATA_DIR, m=machine, id=id)\n",
        "    paths = glob.glob(data_path)\n",
        "\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    print('\\n========== PREDICTING {m}: id_{id} ANOMALY SCORES =========='.format(m=machine, id=id))\n",
        "    \n",
        "    # Cycle through test files\n",
        "    for idx, path in tqdm(enumerate(paths)):\n",
        "\n",
        "        # Load and reshape log-Mel spec \n",
        "        spec = np.load(path)\n",
        "        feature = reshape_spec(spec)\n",
        "\n",
        "        # Make predictions (row by row), calculate the reconstruction error and average it over the entire sample\n",
        "        errors = np.mean(np.square(feature - model.predict(feature)), axis=1)\n",
        "        y_pred.append(np.mean(errors))\n",
        "        y_true.append(0 if 'normal' in path else 1)\n",
        "\n",
        "    auc = metrics.roc_auc_score(y_true, y_pred)\n",
        "    p_auc = metrics.roc_auc_score(y_true, y_pred, max_fpr=MAX_FPR)\n",
        "    csv_lines.append([str(id), auc, p_auc])\n",
        "    [as_csv.append([y_true[idx], score]) for idx, score in enumerate(y_pred)]\n",
        "    performance.append([auc, p_auc])\n",
        "    print(\"AUC : {}\".format(auc))\n",
        "    print(\"pAUC : {}\".format(p_auc))\n",
        "\n",
        "    del X\n",
        "    del y_true\n",
        "    del y_pred\n",
        "    gc.collect()\n",
        "\n",
        "averaged_performance = np.mean(np.array(performance, dtype=float), axis=0)\n",
        "csv_lines.append([\"Average\"] + list(averaged_performance))\n",
        "csv_lines.append([])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J7nKpYhAHpI1",
        "outputId": "5bdd35cf-6676-4d44-a199-383124160a23"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== LOADING fan: id_00 DATA ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "911it [01:44,  8.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training matrix shape: (281499, 640)\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 640)]             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               82048     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 128)              512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 8)                 1032      \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 8)                32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               1152      \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 640)               82560     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 269,992\n",
            "Trainable params: 267,928\n",
            "Non-trainable params: 2,064\n",
            "_________________________________________________________________\n",
            "========== START fan: id_00 TRAINING ==========\n",
            "Epoch 1/100\n",
            "495/495 [==============================] - 13s 18ms/step - loss: 281.4772 - val_loss: 18.8852\n",
            "Epoch 2/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 14.3307 - val_loss: 13.0943\n",
            "Epoch 3/100\n",
            "495/495 [==============================] - 9s 17ms/step - loss: 12.6349 - val_loss: 12.9515\n",
            "Epoch 4/100\n",
            "495/495 [==============================] - 9s 17ms/step - loss: 11.9777 - val_loss: 11.6562\n",
            "Epoch 5/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 11.3363 - val_loss: 11.1362\n",
            "Epoch 6/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 10.8155 - val_loss: 10.7183\n",
            "Epoch 7/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 10.5225 - val_loss: 10.5736\n",
            "Epoch 8/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 10.3343 - val_loss: 10.4930\n",
            "Epoch 9/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 10.1923 - val_loss: 10.5932\n",
            "Epoch 10/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 10.0646 - val_loss: 10.4044\n",
            "Epoch 11/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.9710 - val_loss: 10.3884\n",
            "Epoch 12/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.8846 - val_loss: 10.2973\n",
            "Epoch 13/100\n",
            "495/495 [==============================] - 8s 16ms/step - loss: 9.8144 - val_loss: 10.2948\n",
            "Epoch 14/100\n",
            "495/495 [==============================] - 8s 16ms/step - loss: 9.7542 - val_loss: 10.2636\n",
            "Epoch 15/100\n",
            "495/495 [==============================] - 8s 16ms/step - loss: 9.7035 - val_loss: 10.3850\n",
            "Epoch 16/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.6611 - val_loss: 10.2031\n",
            "Epoch 17/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.6174 - val_loss: 10.4018\n",
            "Epoch 18/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.5757 - val_loss: 10.1292\n",
            "Epoch 19/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.5341 - val_loss: 10.1271\n",
            "Epoch 20/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.4993 - val_loss: 10.3489\n",
            "Epoch 21/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.4743 - val_loss: 10.0452\n",
            "Epoch 22/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.4556 - val_loss: 10.3986\n",
            "Epoch 23/100\n",
            "495/495 [==============================] - 13s 26ms/step - loss: 9.4281 - val_loss: 10.0259\n",
            "Epoch 24/100\n",
            "495/495 [==============================] - 11s 23ms/step - loss: 9.4093 - val_loss: 9.8781\n",
            "Epoch 25/100\n",
            "495/495 [==============================] - 12s 24ms/step - loss: 9.3846 - val_loss: 10.0039\n",
            "Epoch 26/100\n",
            "495/495 [==============================] - 11s 23ms/step - loss: 9.3746 - val_loss: 10.3272\n",
            "Epoch 27/100\n",
            "495/495 [==============================] - 11s 22ms/step - loss: 9.3515 - val_loss: 9.8829\n",
            "Epoch 28/100\n",
            "495/495 [==============================] - 9s 17ms/step - loss: 9.3368 - val_loss: 9.9857\n",
            "Epoch 29/100\n",
            "495/495 [==============================] - 11s 23ms/step - loss: 9.3292 - val_loss: 9.8802\n",
            "Epoch 30/100\n",
            "495/495 [==============================] - 11s 22ms/step - loss: 9.3178 - val_loss: 9.9430\n",
            "Epoch 31/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.2971 - val_loss: 9.8821\n",
            "Epoch 32/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.2922 - val_loss: 9.9163\n",
            "Epoch 33/100\n",
            "495/495 [==============================] - 12s 24ms/step - loss: 9.2820 - val_loss: 9.8684\n",
            "Epoch 34/100\n",
            "495/495 [==============================] - 9s 17ms/step - loss: 9.2750 - val_loss: 9.8016\n",
            "Epoch 35/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.2639 - val_loss: 9.8324\n",
            "Epoch 36/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.2506 - val_loss: 9.8868\n",
            "Epoch 37/100\n",
            "495/495 [==============================] - 9s 17ms/step - loss: 9.2426 - val_loss: 9.8366\n",
            "Epoch 38/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.2374 - val_loss: 9.8731\n",
            "Epoch 39/100\n",
            "495/495 [==============================] - 10s 21ms/step - loss: 9.2300 - val_loss: 9.8465\n",
            "Epoch 40/100\n",
            "495/495 [==============================] - 11s 23ms/step - loss: 9.2194 - val_loss: 9.8049\n",
            "Epoch 41/100\n",
            "495/495 [==============================] - 12s 24ms/step - loss: 9.2149 - val_loss: 9.8743\n",
            "Epoch 42/100\n",
            "495/495 [==============================] - 10s 20ms/step - loss: 9.2089 - val_loss: 9.9119\n",
            "Epoch 43/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.2009 - val_loss: 9.9216\n",
            "Epoch 44/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.1920 - val_loss: 9.8143\n",
            "Epoch 45/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.1877 - val_loss: 9.8137\n",
            "Epoch 46/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.1809 - val_loss: 9.8528\n",
            "Epoch 47/100\n",
            "495/495 [==============================] - 9s 17ms/step - loss: 9.1759 - val_loss: 9.7828\n",
            "Epoch 48/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.1694 - val_loss: 9.8156\n",
            "Epoch 49/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.1674 - val_loss: 9.7613\n",
            "Epoch 50/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.1589 - val_loss: 9.8442\n",
            "Epoch 51/100\n",
            "495/495 [==============================] - 9s 17ms/step - loss: 9.1573 - val_loss: 9.9118\n",
            "Epoch 52/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.1528 - val_loss: 9.7998\n",
            "Epoch 53/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.1508 - val_loss: 9.7951\n",
            "Epoch 54/100\n",
            "495/495 [==============================] - 9s 17ms/step - loss: 9.1441 - val_loss: 9.8271\n",
            "Epoch 55/100\n",
            "495/495 [==============================] - 8s 16ms/step - loss: 9.1415 - val_loss: 9.9304\n",
            "Epoch 56/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.1333 - val_loss: 9.8903\n",
            "Epoch 57/100\n",
            "495/495 [==============================] - 8s 16ms/step - loss: 9.1270 - val_loss: 9.8181\n",
            "Epoch 58/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.1277 - val_loss: 9.7150\n",
            "Epoch 59/100\n",
            "495/495 [==============================] - 8s 16ms/step - loss: 9.1276 - val_loss: 9.7655\n",
            "Epoch 60/100\n",
            "495/495 [==============================] - 8s 16ms/step - loss: 9.1222 - val_loss: 9.7196\n",
            "Epoch 61/100\n",
            "495/495 [==============================] - 8s 16ms/step - loss: 9.1149 - val_loss: 9.6986\n",
            "Epoch 62/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.1129 - val_loss: 9.8448\n",
            "Epoch 63/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.1079 - val_loss: 9.8186\n",
            "Epoch 64/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.1060 - val_loss: 9.7099\n",
            "Epoch 65/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0988 - val_loss: 9.8070\n",
            "Epoch 66/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.1003 - val_loss: 9.7023\n",
            "Epoch 67/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0993 - val_loss: 9.7625\n",
            "Epoch 68/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0949 - val_loss: 9.7284\n",
            "Epoch 69/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0884 - val_loss: 9.8594\n",
            "Epoch 70/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0857 - val_loss: 9.7603\n",
            "Epoch 71/100\n",
            "495/495 [==============================] - 9s 17ms/step - loss: 9.0874 - val_loss: 9.8476\n",
            "Epoch 72/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.0826 - val_loss: 9.7843\n",
            "Epoch 73/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.0811 - val_loss: 9.7187\n",
            "Epoch 74/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.0790 - val_loss: 9.6834\n",
            "Epoch 75/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.0810 - val_loss: 9.7034\n",
            "Epoch 76/100\n",
            "495/495 [==============================] - 9s 17ms/step - loss: 9.0715 - val_loss: 9.7059\n",
            "Epoch 77/100\n",
            "495/495 [==============================] - 8s 17ms/step - loss: 9.0739 - val_loss: 9.6877\n",
            "Epoch 78/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0690 - val_loss: 9.7344\n",
            "Epoch 79/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0664 - val_loss: 9.6682\n",
            "Epoch 80/100\n",
            "495/495 [==============================] - 9s 17ms/step - loss: 9.0652 - val_loss: 9.6813\n",
            "Epoch 81/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0657 - val_loss: 9.7434\n",
            "Epoch 82/100\n",
            "495/495 [==============================] - 9s 17ms/step - loss: 9.0616 - val_loss: 9.6692\n",
            "Epoch 83/100\n",
            "495/495 [==============================] - 9s 17ms/step - loss: 9.0570 - val_loss: 9.6967\n",
            "Epoch 84/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0578 - val_loss: 9.8034\n",
            "Epoch 85/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0570 - val_loss: 9.7616\n",
            "Epoch 86/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0540 - val_loss: 9.7326\n",
            "Epoch 87/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0543 - val_loss: 9.7809\n",
            "Epoch 88/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0487 - val_loss: 9.6667\n",
            "Epoch 89/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0481 - val_loss: 9.7091\n",
            "Epoch 90/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0490 - val_loss: 9.7460\n",
            "Epoch 91/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0442 - val_loss: 9.7883\n",
            "Epoch 92/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0441 - val_loss: 9.6919\n",
            "Epoch 93/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0424 - val_loss: 9.8017\n",
            "Epoch 94/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0422 - val_loss: 9.6655\n",
            "Epoch 95/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0367 - val_loss: 9.6862\n",
            "Epoch 96/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0343 - val_loss: 9.6750\n",
            "Epoch 97/100\n",
            "495/495 [==============================] - 9s 17ms/step - loss: 9.0358 - val_loss: 9.6654\n",
            "Epoch 98/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0363 - val_loss: 9.7075\n",
            "Epoch 99/100\n",
            "495/495 [==============================] - 9s 18ms/step - loss: 9.0323 - val_loss: 9.7483\n",
            "Epoch 100/100\n",
            "495/495 [==============================] - 9s 17ms/step - loss: 9.0324 - val_loss: 9.7254\n",
            "========== END TRAINING ==========\n",
            "\n",
            "========== PREDICTING fan: id_00 ANOMALY SCORES ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "507it [00:55,  9.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC : 0.5506633906633907\n",
            "pAUC : 0.49903013060907797\n",
            "\n",
            "========== LOADING fan: id_02 DATA ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "916it [02:08,  7.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training matrix shape: (283044, 640)\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 640)]             0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               82048     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 8)                 1032      \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 8)                32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 128)               1152      \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_17 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 640)               82560     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 269,992\n",
            "Trainable params: 267,928\n",
            "Non-trainable params: 2,064\n",
            "_________________________________________________________________\n",
            "========== START fan: id_02 TRAINING ==========\n",
            "Epoch 1/100\n",
            "498/498 [==============================] - 12s 18ms/step - loss: 234.8225 - val_loss: 17.6024\n",
            "Epoch 2/100\n",
            "498/498 [==============================] - 9s 17ms/step - loss: 12.2803 - val_loss: 14.2166\n",
            "Epoch 3/100\n",
            "498/498 [==============================] - 9s 19ms/step - loss: 11.2936 - val_loss: 11.6479\n",
            "Epoch 4/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 10.8505 - val_loss: 10.9497\n",
            "Epoch 5/100\n",
            "498/498 [==============================] - 8s 17ms/step - loss: 10.4547 - val_loss: 10.5287\n",
            "Epoch 6/100\n",
            "498/498 [==============================] - 8s 16ms/step - loss: 10.1974 - val_loss: 10.3651\n",
            "Epoch 7/100\n",
            "498/498 [==============================] - 11s 23ms/step - loss: 9.9912 - val_loss: 10.0801\n",
            "Epoch 8/100\n",
            "498/498 [==============================] - 11s 23ms/step - loss: 9.8281 - val_loss: 9.8451\n",
            "Epoch 9/100\n",
            "498/498 [==============================] - 12s 23ms/step - loss: 9.7168 - val_loss: 9.7545\n",
            "Epoch 10/100\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 9.6439 - val_loss: 9.8260\n",
            "Epoch 11/100\n",
            "498/498 [==============================] - 11s 23ms/step - loss: 9.5844 - val_loss: 9.6956\n",
            "Epoch 12/100\n",
            "498/498 [==============================] - 12s 23ms/step - loss: 9.5356 - val_loss: 9.5929\n",
            "Epoch 13/100\n",
            "498/498 [==============================] - 13s 25ms/step - loss: 9.4914 - val_loss: 9.7919\n",
            "Epoch 14/100\n",
            "498/498 [==============================] - 12s 23ms/step - loss: 9.4533 - val_loss: 9.6738\n",
            "Epoch 15/100\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 9.4178 - val_loss: 9.4977\n",
            "Epoch 16/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 9.3854 - val_loss: 9.6084\n",
            "Epoch 17/100\n",
            "498/498 [==============================] - 8s 16ms/step - loss: 9.3599 - val_loss: 9.4963\n",
            "Epoch 18/100\n",
            "498/498 [==============================] - 8s 17ms/step - loss: 9.3322 - val_loss: 9.5444\n",
            "Epoch 19/100\n",
            "498/498 [==============================] - 8s 16ms/step - loss: 9.3006 - val_loss: 9.4208\n",
            "Epoch 20/100\n",
            "498/498 [==============================] - 8s 16ms/step - loss: 9.2748 - val_loss: 9.9498\n",
            "Epoch 21/100\n",
            "498/498 [==============================] - 8s 16ms/step - loss: 9.2432 - val_loss: 9.6765\n",
            "Epoch 22/100\n",
            "498/498 [==============================] - 8s 16ms/step - loss: 9.2187 - val_loss: 9.4523\n",
            "Epoch 23/100\n",
            "498/498 [==============================] - 8s 16ms/step - loss: 9.1922 - val_loss: 9.5446\n",
            "Epoch 24/100\n",
            "498/498 [==============================] - 8s 16ms/step - loss: 9.1785 - val_loss: 9.4422\n",
            "Epoch 25/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 9.1575 - val_loss: 9.5468\n",
            "Epoch 26/100\n",
            "498/498 [==============================] - 8s 16ms/step - loss: 9.1463 - val_loss: 9.5771\n",
            "Epoch 27/100\n",
            "498/498 [==============================] - 8s 16ms/step - loss: 9.1341 - val_loss: 9.6616\n",
            "Epoch 28/100\n",
            "498/498 [==============================] - 8s 17ms/step - loss: 9.1203 - val_loss: 12.3552\n",
            "Epoch 29/100\n",
            "498/498 [==============================] - 8s 16ms/step - loss: 9.1101 - val_loss: 9.4407\n",
            "Epoch 30/100\n",
            "498/498 [==============================] - 8s 16ms/step - loss: 9.0981 - val_loss: 9.2443\n",
            "Epoch 31/100\n",
            "498/498 [==============================] - 8s 17ms/step - loss: 9.0888 - val_loss: 9.4130\n",
            "Epoch 32/100\n",
            "498/498 [==============================] - 8s 17ms/step - loss: 9.0831 - val_loss: 9.3865\n",
            "Epoch 33/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 9.0724 - val_loss: 9.3165\n",
            "Epoch 34/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 9.0638 - val_loss: 9.3550\n",
            "Epoch 35/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 9.0594 - val_loss: 9.3990\n",
            "Epoch 36/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 9.0506 - val_loss: 11.9597\n",
            "Epoch 37/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 9.0461 - val_loss: 9.2574\n",
            "Epoch 38/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 9.0360 - val_loss: 9.2341\n",
            "Epoch 39/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 9.0309 - val_loss: 9.3063\n",
            "Epoch 40/100\n",
            "498/498 [==============================] - 8s 17ms/step - loss: 9.0341 - val_loss: 9.3300\n",
            "Epoch 41/100\n",
            "498/498 [==============================] - 8s 17ms/step - loss: 9.0234 - val_loss: 9.2200\n",
            "Epoch 42/100\n",
            "498/498 [==============================] - 9s 17ms/step - loss: 9.0155 - val_loss: 9.2515\n",
            "Epoch 43/100\n",
            "498/498 [==============================] - 8s 17ms/step - loss: 9.0114 - val_loss: 9.2784\n",
            "Epoch 44/100\n",
            "498/498 [==============================] - 8s 16ms/step - loss: 9.0050 - val_loss: 9.2997\n",
            "Epoch 45/100\n",
            "498/498 [==============================] - 8s 17ms/step - loss: 9.0094 - val_loss: 9.2846\n",
            "Epoch 46/100\n",
            "498/498 [==============================] - 8s 16ms/step - loss: 9.0019 - val_loss: 9.1763\n",
            "Epoch 47/100\n",
            "498/498 [==============================] - 8s 16ms/step - loss: 8.9919 - val_loss: 9.2210\n",
            "Epoch 48/100\n",
            "498/498 [==============================] - 8s 17ms/step - loss: 8.9892 - val_loss: 9.2478\n",
            "Epoch 49/100\n",
            "498/498 [==============================] - 8s 16ms/step - loss: 8.9857 - val_loss: 9.1810\n",
            "Epoch 50/100\n",
            "498/498 [==============================] - 8s 17ms/step - loss: 8.9811 - val_loss: 9.1896\n",
            "Epoch 51/100\n",
            "498/498 [==============================] - 8s 17ms/step - loss: 8.9729 - val_loss: 9.2202\n",
            "Epoch 52/100\n",
            "498/498 [==============================] - 8s 17ms/step - loss: 8.9741 - val_loss: 9.1833\n",
            "Epoch 53/100\n",
            "498/498 [==============================] - 8s 17ms/step - loss: 8.9656 - val_loss: 9.1898\n",
            "Epoch 54/100\n",
            "498/498 [==============================] - 9s 17ms/step - loss: 8.9595 - val_loss: 9.1680\n",
            "Epoch 55/100\n",
            "498/498 [==============================] - 9s 17ms/step - loss: 8.9564 - val_loss: 9.2266\n",
            "Epoch 56/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 8.9574 - val_loss: 9.2764\n",
            "Epoch 57/100\n",
            "498/498 [==============================] - 8s 17ms/step - loss: 8.9566 - val_loss: 9.2320\n",
            "Epoch 58/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 8.9524 - val_loss: 9.2450\n",
            "Epoch 59/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 8.9448 - val_loss: 9.1915\n",
            "Epoch 60/100\n",
            "498/498 [==============================] - 9s 17ms/step - loss: 8.9462 - val_loss: 9.3115\n",
            "Epoch 61/100\n",
            "498/498 [==============================] - 8s 17ms/step - loss: 8.9430 - val_loss: 9.1553\n",
            "Epoch 62/100\n",
            "498/498 [==============================] - 9s 17ms/step - loss: 8.9411 - val_loss: 9.2893\n",
            "Epoch 63/100\n",
            "498/498 [==============================] - 9s 17ms/step - loss: 8.9377 - val_loss: 9.1593\n",
            "Epoch 64/100\n",
            "498/498 [==============================] - 8s 16ms/step - loss: 8.9335 - val_loss: 9.1999\n",
            "Epoch 65/100\n",
            "498/498 [==============================] - 8s 17ms/step - loss: 8.9322 - val_loss: 9.1543\n",
            "Epoch 66/100\n",
            "498/498 [==============================] - 8s 17ms/step - loss: 8.9316 - val_loss: 9.2462\n",
            "Epoch 67/100\n",
            "498/498 [==============================] - 9s 17ms/step - loss: 8.9292 - val_loss: 9.1962\n",
            "Epoch 68/100\n",
            "498/498 [==============================] - 9s 17ms/step - loss: 8.9285 - val_loss: 9.2360\n",
            "Epoch 69/100\n",
            "498/498 [==============================] - 9s 17ms/step - loss: 8.9257 - val_loss: 9.5806\n",
            "Epoch 70/100\n",
            "498/498 [==============================] - 9s 17ms/step - loss: 8.9202 - val_loss: 9.1319\n",
            "Epoch 71/100\n",
            "498/498 [==============================] - 9s 17ms/step - loss: 8.9182 - val_loss: 9.1739\n",
            "Epoch 72/100\n",
            "498/498 [==============================] - 8s 17ms/step - loss: 8.9222 - val_loss: 9.2070\n",
            "Epoch 73/100\n",
            "498/498 [==============================] - 9s 17ms/step - loss: 8.9148 - val_loss: 9.1788\n",
            "Epoch 74/100\n",
            "498/498 [==============================] - 9s 17ms/step - loss: 8.9156 - val_loss: 9.1542\n",
            "Epoch 75/100\n",
            "498/498 [==============================] - 8s 17ms/step - loss: 8.9152 - val_loss: 9.1796\n",
            "Epoch 76/100\n",
            "498/498 [==============================] - 9s 17ms/step - loss: 8.9122 - val_loss: 9.1287\n",
            "Epoch 77/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 8.9102 - val_loss: 9.1535\n",
            "Epoch 78/100\n",
            "498/498 [==============================] - 9s 17ms/step - loss: 8.9051 - val_loss: 9.1838\n",
            "Epoch 79/100\n",
            "498/498 [==============================] - 9s 17ms/step - loss: 8.9049 - val_loss: 9.1681\n",
            "Epoch 80/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 8.9013 - val_loss: 9.1638\n",
            "Epoch 81/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 8.8991 - val_loss: 9.2292\n",
            "Epoch 82/100\n",
            "498/498 [==============================] - 9s 19ms/step - loss: 8.8983 - val_loss: 9.1606\n",
            "Epoch 83/100\n",
            "498/498 [==============================] - 9s 19ms/step - loss: 8.8968 - val_loss: 9.1956\n",
            "Epoch 84/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 8.8927 - val_loss: 9.1408\n",
            "Epoch 85/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 8.8935 - val_loss: 9.1549\n",
            "Epoch 86/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 8.8913 - val_loss: 9.1204\n",
            "Epoch 87/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 8.8914 - val_loss: 9.2178\n",
            "Epoch 88/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 8.8884 - val_loss: 9.1638\n",
            "Epoch 89/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 8.8853 - val_loss: 9.1287\n",
            "Epoch 90/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 8.8879 - val_loss: 9.2046\n",
            "Epoch 91/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 8.8839 - val_loss: 9.1519\n",
            "Epoch 92/100\n",
            "498/498 [==============================] - 9s 19ms/step - loss: 8.8820 - val_loss: 9.1740\n",
            "Epoch 93/100\n",
            "498/498 [==============================] - 9s 19ms/step - loss: 8.8782 - val_loss: 9.1100\n",
            "Epoch 94/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 8.8799 - val_loss: 9.2090\n",
            "Epoch 95/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 8.8765 - val_loss: 9.1312\n",
            "Epoch 96/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 8.8756 - val_loss: 9.1158\n",
            "Epoch 97/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 8.8793 - val_loss: 9.2672\n",
            "Epoch 98/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 8.8852 - val_loss: 9.1394\n",
            "Epoch 99/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 8.8741 - val_loss: 9.0692\n",
            "Epoch 100/100\n",
            "498/498 [==============================] - 9s 18ms/step - loss: 8.8724 - val_loss: 9.1365\n",
            "========== END TRAINING ==========\n",
            "\n",
            "========== PREDICTING fan: id_02 ANOMALY SCORES ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "459it [00:54,  8.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC : 0.8033147632311978\n",
            "pAUC : 0.6139862190294678\n",
            "\n",
            "========== LOADING fan: id_04 DATA ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "933it [02:12,  7.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training matrix shape: (288297, 640)\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 640)]             0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 128)               82048     \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_18 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_19 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_20 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_21 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 8)                 1032      \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 8)                32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_22 (Activation)  (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 128)               1152      \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_23 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_24 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_24 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_25 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_25 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_26 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 640)               82560     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 269,992\n",
            "Trainable params: 267,928\n",
            "Non-trainable params: 2,064\n",
            "_________________________________________________________________\n",
            "========== START fan: id_04 TRAINING ==========\n",
            "Epoch 1/100\n",
            "507/507 [==============================] - 11s 17ms/step - loss: 252.2235 - val_loss: 16.3367\n",
            "Epoch 2/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 13.0982 - val_loss: 12.8174\n",
            "Epoch 3/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 11.8212 - val_loss: 11.5061\n",
            "Epoch 4/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 11.1629 - val_loss: 10.8027\n",
            "Epoch 5/100\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 10.6432 - val_loss: 10.4189\n",
            "Epoch 6/100\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 10.3261 - val_loss: 10.3781\n",
            "Epoch 7/100\n",
            "507/507 [==============================] - 8s 17ms/step - loss: 10.1580 - val_loss: 10.1358\n",
            "Epoch 8/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 10.0317 - val_loss: 9.9274\n",
            "Epoch 9/100\n",
            "507/507 [==============================] - 8s 17ms/step - loss: 9.9245 - val_loss: 9.9519\n",
            "Epoch 10/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.8419 - val_loss: 9.8966\n",
            "Epoch 11/100\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 9.7779 - val_loss: 9.8350\n",
            "Epoch 12/100\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 9.7201 - val_loss: 9.8553\n",
            "Epoch 13/100\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 9.6720 - val_loss: 9.9252\n",
            "Epoch 14/100\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 9.6216 - val_loss: 9.7298\n",
            "Epoch 15/100\n",
            "507/507 [==============================] - 8s 17ms/step - loss: 9.5779 - val_loss: 9.7333\n",
            "Epoch 16/100\n",
            "507/507 [==============================] - 8s 17ms/step - loss: 9.5376 - val_loss: 9.7732\n",
            "Epoch 17/100\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 9.5006 - val_loss: 9.7049\n",
            "Epoch 18/100\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 9.4686 - val_loss: 9.6441\n",
            "Epoch 19/100\n",
            "507/507 [==============================] - 8s 17ms/step - loss: 9.4417 - val_loss: 9.8521\n",
            "Epoch 20/100\n",
            "507/507 [==============================] - 8s 17ms/step - loss: 9.4205 - val_loss: 9.8557\n",
            "Epoch 21/100\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 9.3943 - val_loss: 9.6127\n",
            "Epoch 22/100\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 9.3799 - val_loss: 9.7931\n",
            "Epoch 23/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.3608 - val_loss: 9.6310\n",
            "Epoch 24/100\n",
            "507/507 [==============================] - 8s 17ms/step - loss: 9.3450 - val_loss: 9.7550\n",
            "Epoch 25/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.3248 - val_loss: 9.6822\n",
            "Epoch 26/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.3113 - val_loss: 9.5709\n",
            "Epoch 27/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.3088 - val_loss: 10.6153\n",
            "Epoch 28/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.2873 - val_loss: 9.6298\n",
            "Epoch 29/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.2815 - val_loss: 9.5999\n",
            "Epoch 30/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.2633 - val_loss: 9.5948\n",
            "Epoch 31/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.2577 - val_loss: 9.5545\n",
            "Epoch 32/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.2470 - val_loss: 9.5274\n",
            "Epoch 33/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.2379 - val_loss: 9.4842\n",
            "Epoch 34/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.2354 - val_loss: 9.4685\n",
            "Epoch 35/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.2214 - val_loss: 9.4624\n",
            "Epoch 36/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.2137 - val_loss: 11.1342\n",
            "Epoch 37/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.2099 - val_loss: 9.5040\n",
            "Epoch 38/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.1995 - val_loss: 9.6230\n",
            "Epoch 39/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.1948 - val_loss: 9.5956\n",
            "Epoch 40/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.1900 - val_loss: 9.4799\n",
            "Epoch 41/100\n",
            "507/507 [==============================] - 9s 19ms/step - loss: 9.1808 - val_loss: 9.6132\n",
            "Epoch 42/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.1751 - val_loss: 9.4024\n",
            "Epoch 43/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.1698 - val_loss: 9.6996\n",
            "Epoch 44/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.1653 - val_loss: 9.4563\n",
            "Epoch 45/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.1574 - val_loss: 9.6329\n",
            "Epoch 46/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.1506 - val_loss: 9.4243\n",
            "Epoch 47/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.1477 - val_loss: 9.4377\n",
            "Epoch 48/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.1408 - val_loss: 9.4013\n",
            "Epoch 49/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.1381 - val_loss: 9.4926\n",
            "Epoch 50/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.1346 - val_loss: 9.4537\n",
            "Epoch 51/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.1265 - val_loss: 9.4417\n",
            "Epoch 52/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.1196 - val_loss: 9.4802\n",
            "Epoch 53/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.1168 - val_loss: 9.3718\n",
            "Epoch 54/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.1127 - val_loss: 9.4103\n",
            "Epoch 55/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.1135 - val_loss: 9.4069\n",
            "Epoch 56/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.1052 - val_loss: 9.4736\n",
            "Epoch 57/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.0963 - val_loss: 9.3985\n",
            "Epoch 58/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.0963 - val_loss: 9.4541\n",
            "Epoch 59/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.0900 - val_loss: 9.3452\n",
            "Epoch 60/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0859 - val_loss: 9.4648\n",
            "Epoch 61/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0884 - val_loss: 9.4334\n",
            "Epoch 62/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0796 - val_loss: 9.4073\n",
            "Epoch 63/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0791 - val_loss: 9.4356\n",
            "Epoch 64/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0705 - val_loss: 9.4180\n",
            "Epoch 65/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0661 - val_loss: 9.3574\n",
            "Epoch 66/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0641 - val_loss: 9.4183\n",
            "Epoch 67/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0623 - val_loss: 9.3783\n",
            "Epoch 68/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0568 - val_loss: 9.4008\n",
            "Epoch 69/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0528 - val_loss: 9.3783\n",
            "Epoch 70/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0517 - val_loss: 9.3763\n",
            "Epoch 71/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0522 - val_loss: 9.4068\n",
            "Epoch 72/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.0471 - val_loss: 9.4201\n",
            "Epoch 73/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.0451 - val_loss: 9.3664\n",
            "Epoch 74/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.0431 - val_loss: 9.4444\n",
            "Epoch 75/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.0386 - val_loss: 9.3698\n",
            "Epoch 76/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.0390 - val_loss: 9.4577\n",
            "Epoch 77/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.0326 - val_loss: 9.3436\n",
            "Epoch 78/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.0352 - val_loss: 9.3945\n",
            "Epoch 79/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.0302 - val_loss: 9.3820\n",
            "Epoch 80/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.0303 - val_loss: 9.4201\n",
            "Epoch 81/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.0299 - val_loss: 9.3421\n",
            "Epoch 82/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0249 - val_loss: 9.3604\n",
            "Epoch 83/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0236 - val_loss: 9.3478\n",
            "Epoch 84/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0234 - val_loss: 9.4464\n",
            "Epoch 85/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.0159 - val_loss: 9.3662\n",
            "Epoch 86/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0172 - val_loss: 9.3967\n",
            "Epoch 87/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0188 - val_loss: 9.3433\n",
            "Epoch 88/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0158 - val_loss: 9.3833\n",
            "Epoch 89/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0140 - val_loss: 9.3884\n",
            "Epoch 90/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0114 - val_loss: 9.3473\n",
            "Epoch 91/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0116 - val_loss: 9.3385\n",
            "Epoch 92/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0106 - val_loss: 9.3434\n",
            "Epoch 93/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0108 - val_loss: 9.3904\n",
            "Epoch 94/100\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 9.0073 - val_loss: 9.3273\n",
            "Epoch 95/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.0017 - val_loss: 9.3862\n",
            "Epoch 96/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.0058 - val_loss: 9.4282\n",
            "Epoch 97/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.0027 - val_loss: 9.4146\n",
            "Epoch 98/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.0009 - val_loss: 9.3091\n",
            "Epoch 99/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 9.0004 - val_loss: 9.3158\n",
            "Epoch 100/100\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 8.9972 - val_loss: 9.4028\n",
            "========== END TRAINING ==========\n",
            "\n",
            "========== PREDICTING fan: id_04 ANOMALY SCORES ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "448it [00:52,  8.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC : 0.6384482758620689\n",
            "pAUC : 0.5390199637023594\n",
            "\n",
            "========== LOADING fan: id_06 DATA ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "915it [02:29,  6.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training matrix shape: (282735, 640)\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 640)]             0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 128)               82048     \n",
            "                                                                 \n",
            " batch_normalization_27 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_28 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_28 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_29 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_29 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_30 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_30 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 8)                 1032      \n",
            "                                                                 \n",
            " batch_normalization_31 (Bat  (None, 8)                32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_31 (Activation)  (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 128)               1152      \n",
            "                                                                 \n",
            " batch_normalization_32 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_32 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_33 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_33 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_34 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_34 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_35 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_35 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 640)               82560     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 269,992\n",
            "Trainable params: 267,928\n",
            "Non-trainable params: 2,064\n",
            "_________________________________________________________________\n",
            "========== START fan: id_06 TRAINING ==========\n",
            "Epoch 1/100\n",
            "497/497 [==============================] - 11s 17ms/step - loss: 262.1123 - val_loss: 17.3004\n",
            "Epoch 2/100\n",
            "497/497 [==============================] - 9s 17ms/step - loss: 12.8942 - val_loss: 14.3466\n",
            "Epoch 3/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 11.4050 - val_loss: 11.4515\n",
            "Epoch 4/100\n",
            "497/497 [==============================] - 9s 17ms/step - loss: 10.7607 - val_loss: 10.9839\n",
            "Epoch 5/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 10.3745 - val_loss: 10.4306\n",
            "Epoch 6/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 10.1304 - val_loss: 10.2079\n",
            "Epoch 7/100\n",
            "497/497 [==============================] - 9s 17ms/step - loss: 9.9553 - val_loss: 10.1033\n",
            "Epoch 8/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 9.7862 - val_loss: 9.9160\n",
            "Epoch 9/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 9.6596 - val_loss: 9.7331\n",
            "Epoch 10/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 9.5564 - val_loss: 9.9413\n",
            "Epoch 11/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 9.4688 - val_loss: 9.5148\n",
            "Epoch 12/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 9.4010 - val_loss: 9.6327\n",
            "Epoch 13/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 9.3381 - val_loss: 9.4797\n",
            "Epoch 14/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 9.2791 - val_loss: 9.4403\n",
            "Epoch 15/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 9.2234 - val_loss: 9.5360\n",
            "Epoch 16/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 9.1820 - val_loss: 9.6103\n",
            "Epoch 17/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 9.1430 - val_loss: 9.4213\n",
            "Epoch 18/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 9.1026 - val_loss: 9.6709\n",
            "Epoch 19/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 9.0715 - val_loss: 9.2479\n",
            "Epoch 20/100\n",
            "497/497 [==============================] - 8s 16ms/step - loss: 9.0396 - val_loss: 11.0728\n",
            "Epoch 21/100\n",
            "497/497 [==============================] - 8s 16ms/step - loss: 9.0023 - val_loss: 9.4167\n",
            "Epoch 22/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.9685 - val_loss: 9.2953\n",
            "Epoch 23/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.9431 - val_loss: 9.5435\n",
            "Epoch 24/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.9200 - val_loss: 9.1176\n",
            "Epoch 25/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.9003 - val_loss: 9.3830\n",
            "Epoch 26/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.8850 - val_loss: 9.1800\n",
            "Epoch 27/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.8715 - val_loss: 19.5327\n",
            "Epoch 28/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.8595 - val_loss: 9.1066\n",
            "Epoch 29/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.8385 - val_loss: 9.0755\n",
            "Epoch 30/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.8348 - val_loss: 15.7855\n",
            "Epoch 31/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.8228 - val_loss: 9.1752\n",
            "Epoch 32/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.8094 - val_loss: 9.0704\n",
            "Epoch 33/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.8020 - val_loss: 9.8688\n",
            "Epoch 34/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.7918 - val_loss: 9.0734\n",
            "Epoch 35/100\n",
            "497/497 [==============================] - 9s 17ms/step - loss: 8.7889 - val_loss: 9.1653\n",
            "Epoch 36/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.7817 - val_loss: 8.9990\n",
            "Epoch 37/100\n",
            "497/497 [==============================] - 9s 17ms/step - loss: 8.7690 - val_loss: 9.5472\n",
            "Epoch 38/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.7627 - val_loss: 9.0703\n",
            "Epoch 39/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.7589 - val_loss: 8.9837\n",
            "Epoch 40/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.7523 - val_loss: 9.0725\n",
            "Epoch 41/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.7485 - val_loss: 9.0503\n",
            "Epoch 42/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.7389 - val_loss: 8.9969\n",
            "Epoch 43/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.7349 - val_loss: 9.0597\n",
            "Epoch 44/100\n",
            "497/497 [==============================] - 9s 17ms/step - loss: 8.7243 - val_loss: 9.1325\n",
            "Epoch 45/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.7260 - val_loss: 9.1738\n",
            "Epoch 46/100\n",
            "497/497 [==============================] - 8s 16ms/step - loss: 8.7216 - val_loss: 8.9646\n",
            "Epoch 47/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.7143 - val_loss: 8.9534\n",
            "Epoch 48/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.7083 - val_loss: 8.9745\n",
            "Epoch 49/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.7077 - val_loss: 8.9958\n",
            "Epoch 50/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.7019 - val_loss: 8.9454\n",
            "Epoch 51/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.6922 - val_loss: 8.9852\n",
            "Epoch 52/100\n",
            "497/497 [==============================] - 9s 17ms/step - loss: 8.6944 - val_loss: 8.9682\n",
            "Epoch 53/100\n",
            "497/497 [==============================] - 9s 17ms/step - loss: 8.6893 - val_loss: 8.9548\n",
            "Epoch 54/100\n",
            "497/497 [==============================] - 9s 17ms/step - loss: 8.6849 - val_loss: 9.4518\n",
            "Epoch 55/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.6814 - val_loss: 9.1322\n",
            "Epoch 56/100\n",
            "497/497 [==============================] - 8s 16ms/step - loss: 8.6758 - val_loss: 8.9618\n",
            "Epoch 57/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6720 - val_loss: 8.9698\n",
            "Epoch 58/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6697 - val_loss: 9.0701\n",
            "Epoch 59/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6648 - val_loss: 8.9888\n",
            "Epoch 60/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6673 - val_loss: 8.9981\n",
            "Epoch 61/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6599 - val_loss: 8.9484\n",
            "Epoch 62/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6585 - val_loss: 8.9557\n",
            "Epoch 63/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6531 - val_loss: 9.0284\n",
            "Epoch 64/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6516 - val_loss: 9.0038\n",
            "Epoch 65/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6487 - val_loss: 8.9388\n",
            "Epoch 66/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.6495 - val_loss: 9.0503\n",
            "Epoch 67/100\n",
            "497/497 [==============================] - 8s 16ms/step - loss: 8.6449 - val_loss: 8.9211\n",
            "Epoch 68/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6409 - val_loss: 8.9285\n",
            "Epoch 69/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6406 - val_loss: 9.0261\n",
            "Epoch 70/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6375 - val_loss: 11.0058\n",
            "Epoch 71/100\n",
            "497/497 [==============================] - 8s 16ms/step - loss: 8.6375 - val_loss: 8.9269\n",
            "Epoch 72/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.6322 - val_loss: 8.8892\n",
            "Epoch 73/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6295 - val_loss: 8.8900\n",
            "Epoch 74/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6304 - val_loss: 9.0631\n",
            "Epoch 75/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6247 - val_loss: 8.9387\n",
            "Epoch 76/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6258 - val_loss: 8.9381\n",
            "Epoch 77/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6235 - val_loss: 8.9713\n",
            "Epoch 78/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6224 - val_loss: 8.9270\n",
            "Epoch 79/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6192 - val_loss: 8.9505\n",
            "Epoch 80/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6191 - val_loss: 8.8768\n",
            "Epoch 81/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.6147 - val_loss: 8.8904\n",
            "Epoch 82/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.6146 - val_loss: 8.9118\n",
            "Epoch 83/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6143 - val_loss: 8.9527\n",
            "Epoch 84/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6093 - val_loss: 8.8792\n",
            "Epoch 85/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6091 - val_loss: 8.8625\n",
            "Epoch 86/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.6068 - val_loss: 8.9234\n",
            "Epoch 87/100\n",
            "497/497 [==============================] - 9s 17ms/step - loss: 8.6043 - val_loss: 8.8936\n",
            "Epoch 88/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6028 - val_loss: 8.8973\n",
            "Epoch 89/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6005 - val_loss: 8.9573\n",
            "Epoch 90/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6014 - val_loss: 8.8907\n",
            "Epoch 91/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.6006 - val_loss: 8.8879\n",
            "Epoch 92/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.5973 - val_loss: 8.8975\n",
            "Epoch 93/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.5954 - val_loss: 8.8730\n",
            "Epoch 94/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.5946 - val_loss: 8.9337\n",
            "Epoch 95/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.5943 - val_loss: 8.9711\n",
            "Epoch 96/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.5931 - val_loss: 8.8774\n",
            "Epoch 97/100\n",
            "497/497 [==============================] - 9s 18ms/step - loss: 8.5924 - val_loss: 8.8893\n",
            "Epoch 98/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.5892 - val_loss: 8.9001\n",
            "Epoch 99/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.5889 - val_loss: 8.9346\n",
            "Epoch 100/100\n",
            "497/497 [==============================] - 8s 17ms/step - loss: 8.5875 - val_loss: 8.9005\n",
            "========== END TRAINING ==========\n",
            "\n",
            "========== PREDICTING fan: id_06 ANOMALY SCORES ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "461it [00:53,  8.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC : 0.8742659279778393\n",
            "pAUC : 0.6626330368858434\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output results\n",
        "os.makedirs(RESULT_DIR, exist_ok=True)\n",
        "result_name = '{}_results.csv'.format('fan_autoencoder')\n",
        "as_name = '{}_scores.csv'.format('fan_autoencoder')\n",
        "result_path = os.path.join(RESULT_DIR, result_name)\n",
        "as_path = os.path.join(RESULT_DIR, as_name)\n",
        "print(\"AUC and pAUC results -> {}\".format(result_path))\n",
        "print('Anomaly scores -> {}'.format(as_path))\n",
        "save_csv(save_file_path=result_path, save_data=csv_lines)\n",
        "save_csv(save_file_path=as_path, save_data=as_csv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5M4SXjuGr-jv",
        "outputId": "6b5183c8-5775-4617-f87b-ee0826530421"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC and pAUC results -> ./autoencoder_result/fan_autoencoder_results.csv\n",
            "Anomaly scores -> ./autoencoder_result/fan_autoencoder_scores.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "dcase_autoencoder_baseline.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}